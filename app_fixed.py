import pandas as pd
import numpy as np
from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import tempfile
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from contextlib import asynccontextmanager
import warnings
import joblib

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è
predictor = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    global predictor
    print("üöÄ –ó–∞–ø—É—Å–∫ Heart Disease Prediction...")
    predictor = HeartDiseasePredictor()
    predictor.train_model()
    print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!")
    yield
    # Shutdown
    print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="Heart Disease Prediction", version="1.0", lifespan=lifespan)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤
templates = Jinja2Templates(directory="templates")

class HeartDiseasePredictor:
    def __init__(self):
        self.model = None
        self.feature_names = None
        self.categorical_features = None
        self.numerical_features = None
        self.threshold = 0.454  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∏–∑ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π
        self.model_path = 'heart_disease_model.joblib'
        
    def train_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π"""
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        if self.load_model():
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ —Ñ–∞–π–ª–∞")
            return
        
        print("üìä –û–±—É—á–µ–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_train = pd.read_csv('heart_train.csv')
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_train)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∫–∞–∫ –≤ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π
        columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
        df_clean = df_train.drop(columns=columns_to_drop, errors='ignore')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ –∫—Ä–æ–º–µ —á–∏—Å–ª–æ–≤—ã—Ö)
        categorical_features = ['Diabetes', 'Family History', 'Obesity', 'Alcohol Consumption', 
                              'Diet', 'Previous Heart Problems', 'Medication Use', 'Stress Level',
                              'Physical Activity Days Per Week', 'Sleep Hours Per Day', 'Gender']
        
        # –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
        numerical_features = [col for col in df_clean.columns if col not in categorical_features]
        
        print(f"üìã –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(categorical_features)}")
        print(f"üìä –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(numerical_features)}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', 'passthrough', numerical_features),
                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore', min_frequency=1), categorical_features)
            ])
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        self.model = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(
                n_estimators=2000,
                max_depth=10,
                class_weight='balanced',
                random_state=42
            ))
        ])
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        X = df_clean
        y = df_train['Heart Attack Risk (Binary)']
        
        self.model.fit(X, y)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.feature_names = df_clean.columns.tolist()
        self.categorical_features = categorical_features
        self.numerical_features = numerical_features
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        self.save_model()
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ —Å {len(self.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        print(f"üéØ –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {self.threshold}")
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        try:
            model_data = {
                'model': self.model,
                'feature_names': self.feature_names,
                'categorical_features': self.categorical_features,
                'numerical_features': self.numerical_features,
                'threshold': self.threshold
            }
            joblib.dump(model_data, self.model_path)
            print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {self.model_path}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        try:
            if not os.path.exists(self.model_path):
                print(f"üìÅ –§–∞–π–ª –º–æ–¥–µ–ª–∏ {self.model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False
            
            model_data = joblib.load(self.model_path)
            self.model = model_data['model']
            self.feature_names = model_data['feature_names']
            self.categorical_features = model_data['categorical_features']
            self.numerical_features = model_data['numerical_features']
            self.threshold = model_data['threshold']
            
            print(f"üìÅ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {self.model_path}")
            return True
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
        
    def predict_single(self, data_dict):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame([data_dict])
            
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
            df_clean = df.drop(columns=columns_to_drop, errors='ignore')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            for col in self.categorical_features:
                if col in df_clean.columns:
                    if col == 'Gender':
                        # Gender –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                        df_clean[col] = df_clean[col].astype(str)
                    elif col in ['Physical Activity Days Per Week', 'Sleep Hours Per Day']:
                        # –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ float
            for col in self.numerical_features:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            missing_cols = set(self.feature_names) - set(df_clean.columns)
            for col in missing_cols:
                df_clean[col] = 0  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            df_clean = df_clean[self.feature_names]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            proba = self.model.predict_proba(df_clean)[0]
            risk_probability = proba[1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            prediction = 1 if risk_probability >= self.threshold else 0
            
            return {
                'prediction': int(prediction),
                'probability': float(risk_probability),
                'threshold': self.threshold
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {'prediction': 0, 'probability': 0.0, 'threshold': self.threshold}
    
    def predict_batch(self, df):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–∞—Ç—á–∞ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
            df_clean = df.drop(columns=columns_to_drop, errors='ignore')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            for col in self.categorical_features:
                if col in df_clean.columns:
                    if col == 'Gender':
                        # Gender –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                        df_clean[col] = df_clean[col].astype(str)
                    elif col in ['Physical Activity Days Per Week', 'Sleep Hours Per Day']:
                        # –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ float
            for col in self.numerical_features:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            missing_cols = set(self.feature_names) - set(df_clean.columns)
            for col in missing_cols:
                df_clean[col] = 0  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            df_clean = df_clean[self.feature_names]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            probas = self.model.predict_proba(df_clean)
            risk_probabilities = probas[:, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            predictions = (risk_probabilities >= self.threshold).astype(int)
            
            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            print(f"üìä –í—Å–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {len(predictions)}")
            print(f"üìä –ü—Ä–æ–≥–Ω–æ–∑–æ–≤ 0: {sum(predictions == 0)}")
            print(f"üìä –ü—Ä–æ–≥–Ω–æ–∑–æ–≤ 1: {sum(predictions == 1)}")
            print(f"üéØ –ü–æ—Ä–æ–≥: {self.threshold}")
            print(f"üìä –ü—Ä–∏–º–µ—Ä—ã –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π: {risk_probabilities[:5]}")
            
            return predictions.tolist()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return [0] * len(df)

@app.get("/", response_class=HTMLResponse)
async def main_page(request: Request):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/api/models")
async def get_model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    return {
        "model_type": "random_forest",
        "threshold": predictor.threshold,
        "features_count": len(predictor.feature_names) if predictor.feature_names else 0,
        "categorical_features": predictor.categorical_features,
        "numerical_features": predictor.numerical_features
    }

@app.post("/api/predict/single")
async def predict_single(data: dict):
    """–û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        result = predictor.predict_single(data)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/predict/file")
async def predict_file(file: UploadFile = File(...)):
    """–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–π–ª–∞"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="–¢–æ–ª—å–∫–æ CSV —Ñ–∞–π–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        df = pd.read_csv(file.file)
        
        if 'id' not in df.columns:
            raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü 'id'")
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ {file.filename}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã
        predictions = predictor.predict_batch(df)
        
        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã API:")
        print(f"üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–∑—Ü–æ–≤: {len(df)}")
        print(f"üìä –í—Å–µ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–æ–≤: {len(predictions)}")
        print(f"üìä –ü—Ä–æ–≥–Ω–æ–∑–æ–≤ 0: {predictions.count(0)}")
        print(f"üìä –ü—Ä–æ–≥–Ω–æ–∑–æ–≤ 1: {predictions.count(1)}")
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_df = pd.DataFrame({
            'id': df['id'],
            'prediction': predictions
        })
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print(f"üìä –†–∞–∑–º–µ—Ä result_df: {len(result_df)}")
        print(f"üìä –ö–æ–ª–æ–Ω–∫–∏ result_df: {result_df.columns.tolist()}")
        print(f"üìä –ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫ result_df:")
        print(result_df.head())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
        data_records = result_df.to_dict('records')
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ data: {len(data_records)}")
        print(f"üìä –ü–µ—Ä–≤—ã–µ 5 –∑–∞–ø–∏—Å–µ–π –≤ data:")
        for i, record in enumerate(data_records[:5]):
            print(f"  –ó–∞–ø–∏—Å—å {i}: id={record['id']}, prediction={record['prediction']} (—Ç–∏–ø: {type(record['prediction'])})")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –ø—Ä–æ–≥–Ω–æ–∑—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
        zeros_count = sum(1 for record in data_records if record['prediction'] == 0)
        ones_count = sum(1 for record in data_records if record['prediction'] == 1)
        print(f"üìä –í data_records: –Ω—É–ª–µ–π={zeros_count}, –µ–¥–∏–Ω–∏—Ü={ones_count}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç None –∏–ª–∏ undefined –∑–Ω–∞—á–µ–Ω–∏–π
        invalid_count = sum(1 for record in data_records if record['prediction'] is None or record['prediction'] == 'undefined')
        if invalid_count > 0:
            print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω–æ {invalid_count} –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π!")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        return {
            "success": True,
            "samples": len(df),
            "predictions": predictions,
            "data": data_records
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000) 