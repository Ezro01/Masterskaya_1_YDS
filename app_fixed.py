import pandas as pd
import numpy as np
from fastapi import FastAPI, File, UploadFile, HTTPException, Request
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
import uvicorn
import tempfile
import os
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from contextlib import asynccontextmanager
import warnings

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—è
predictor = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    global predictor
    print("üöÄ –ó–∞–ø—É—Å–∫ Heart Disease Prediction...")
    predictor = HeartDiseasePredictor()
    predictor.train_model()
    print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!")
    yield
    # Shutdown
    print("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")

# –°–æ–∑–¥–∞–µ–º FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(title="Heart Disease Prediction", version="1.0", lifespan=lifespan)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∞–±–ª–æ–Ω–æ–≤
templates = Jinja2Templates(directory="templates")

class HeartDiseasePredictor:
    def __init__(self):
        self.model = None
        self.feature_names = None
        self.threshold = 0.454  # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –∏–∑ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π
        
    def train_model(self):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π"""
        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df_train = pd.read_csv('heart_train.csv')
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df_train)} —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤")
        
        # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∫–∞–∫ –≤ –º–∞—Å—Ç–µ—Ä—Å–∫–æ–π
        columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
        df_clean = df_train.drop(columns=columns_to_drop, errors='ignore')
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ –∫—Ä–æ–º–µ —á–∏—Å–ª–æ–≤—ã—Ö)
        categorical_features = ['Diabetes', 'Family History', 'Obesity', 'Alcohol Consumption', 
                              'Diet', 'Previous Heart Problems', 'Medication Use', 'Stress Level',
                              'Physical Activity Days Per Week', 'Sleep Hours Per Day', 'Gender']
        
        # –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
        numerical_features = [col for col in df_clean.columns if col not in categorical_features]
        
        print(f"üìã –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(categorical_features)}")
        print(f"üìä –ß–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {len(numerical_features)}")
        
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        preprocessor = ColumnTransformer(
            transformers=[
                ('num', 'passthrough', numerical_features),
                ('cat', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore', min_frequency=1), categorical_features)
            ])
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
        self.model = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', RandomForestClassifier(
                n_estimators=2000,
                max_depth=10,
                class_weight='balanced',
                random_state=42
            ))
        ])
        
        # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å
        X = df_clean
        y = df_train['Heart Attack Risk (Binary)']
        
        self.model.fit(X, y)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.feature_names = df_clean.columns.tolist()
        self.categorical_features = categorical_features
        self.numerical_features = numerical_features
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —Å {len(self.feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        print(f"üéØ –ü–æ—Ä–æ–≥ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {self.threshold}")
        
    def predict_single(self, data_dict):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–∞—Ü–∏–µ–Ω—Ç–∞"""
        try:
            # –°–æ–∑–¥–∞–µ–º DataFrame
            df = pd.DataFrame([data_dict])
            
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
            df_clean = df.drop(columns=columns_to_drop, errors='ignore')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            for col in self.categorical_features:
                if col in df_clean.columns:
                    if col == 'Gender':
                        # Gender –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                        df_clean[col] = df_clean[col].astype(str)
                    elif col in ['Physical Activity Days Per Week', 'Sleep Hours Per Day']:
                        # –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ float
            for col in self.numerical_features:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            missing_cols = set(self.feature_names) - set(df_clean.columns)
            for col in missing_cols:
                df_clean[col] = 0  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            df_clean = df_clean[self.feature_names]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            proba = self.model.predict_proba(df_clean)[0]
            risk_probability = proba[1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            prediction = 1 if risk_probability >= self.threshold else 0
            
            return {
                'prediction': int(prediction),
                'probability': float(risk_probability),
                'threshold': self.threshold
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {'prediction': 0, 'probability': 0.0, 'threshold': self.threshold}
    
    def predict_batch(self, df):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –±–∞—Ç—á–∞ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –£–±–∏—Ä–∞–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
            columns_to_drop = ['Unnamed: 0', 'id', 'Heart Attack Risk (Binary)', 'Smoking', 'Blood sugar', 'CK-MB', 'Troponin']
            df_clean = df.drop(columns=columns_to_drop, errors='ignore')
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã
            for col in self.categorical_features:
                if col in df_clean.columns:
                    if col == 'Gender':
                        # Gender –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π
                        df_clean[col] = df_clean[col].astype(str)
                    elif col in ['Physical Activity Days Per Week', 'Sleep Hours Per Day']:
                        # –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
                    else:
                        # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º–∏
                        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0).astype(int)
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤ float
            for col in self.numerical_features:
                if col in df_clean.columns:
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce').fillna(0)
            
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç
            missing_cols = set(self.feature_names) - set(df_clean.columns)
            for col in missing_cols:
                df_clean[col] = 0  # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
            df_clean = df_clean[self.feature_names]
            
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            probas = self.model.predict_proba(df_clean)
            risk_probabilities = probas[:, 1]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤—ã—Å–æ–∫–æ–≥–æ —Ä–∏—Å–∫–∞
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ—Ä–æ–≥
            predictions = (risk_probabilities >= self.threshold).astype(int)
            
            return predictions.tolist()
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return [0] * len(df)

@app.get("/", response_class=HTMLResponse)
async def main_page(request: Request):
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/api/models")
async def get_model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    return {
        "model_type": "random_forest",
        "threshold": predictor.threshold,
        "features_count": len(predictor.feature_names) if predictor.feature_names else 0,
        "categorical_features": predictor.categorical_features,
        "numerical_features": predictor.numerical_features
    }

@app.post("/api/predict/single")
async def predict_single(data: dict):
    """–û–¥–∏–Ω–æ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        result = predictor.predict_single(data)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/predict/file")
async def predict_file(file: UploadFile = File(...)):
    """–ü—Ä–æ–≥–Ω–æ–∑ –¥–ª—è —Ñ–∞–π–ª–∞"""
    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        if not file.filename.endswith('.csv'):
            raise HTTPException(status_code=400, detail="–¢–æ–ª—å–∫–æ CSV —Ñ–∞–π–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è")
        
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        df = pd.read_csv(file.file)
        
        if 'id' not in df.columns:
            raise HTTPException(status_code=400, detail="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å—Ç–æ–ª–±–µ—Ü 'id'")
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ {file.filename}")
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–≥–Ω–æ–∑—ã
        predictions = predictor.predict_batch(df)
        
        # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_df = pd.DataFrame({
            'id': df['id'],
            'prediction': predictions
        })
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
        return {
            "success": True,
            "samples": len(df),
            "predictions": predictions,
            "data": result_df.to_dict('records')
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000) 